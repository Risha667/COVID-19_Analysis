# -*- coding: utf-8 -*-
"""Covide-19_DA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FqI9Dusb62Q1axGnYTJNYWnsKbo-VIdx
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Load each dataset into a DataFrame
burden_behaviours_testing = pd.read_excel("COVID_Burden_Behaviours_Testing.xlsx")
case_fatality_ratios = pd.read_excel("COVID_Case_Fatality_Ratios.xlsx")
cases_deaths = pd.read_excel("COVID_Cases_Deaths.xlsx")
vaccination_data = pd.read_excel("COVID_Vaccination_Data.xlsx")

# Preview the first few rows of each dataset
print("Burden, Behaviours, and Testing")
print(burden_behaviours_testing.head())

print("\nCase Fatality Ratios")
print(case_fatality_ratios.head())

print("\nCases and Deaths")
print(cases_deaths.head())

print("\nVaccination Data")
print(vaccination_data.head())

print(burden_behaviours_testing.info())
print(case_fatality_ratios.info())
print(cases_deaths.info())
print(vaccination_data.info())

print(burden_behaviours_testing.isnull().sum())

# Drop columns with fully missing or irrelevant values
burden_behaviours_testing = burden_behaviours_testing.drop(['flag', 'se', 'ci_lb', 'ci_ub'], axis=1, errors='ignore')

# Drop unnecessary columns
vaccination_data = vaccination_data.drop(['flag', 'se', 'ci_lb', 'ci_ub'], axis=1, errors='ignore')

# Drop unnecessary columns
case_fatality_ratios = case_fatality_ratios.drop(['flag', 'se', 'ci_lb', 'ci_ub'], axis=1, errors='ignore')

# Drop unnecessary columns
case_fatality_ratios = case_fatality_ratios.drop(['flag', 'se', 'ci_lb', 'ci_ub'], axis=1, errors='ignore')

# Drop unnecessary columns
cases_deaths = cases_deaths.drop(['flag', 'se', 'ci_lb', 'ci_ub'], axis=1, errors='ignore')

# Convert date column to datetime
burden_behaviours_testing['date'] = pd.to_datetime(burden_behaviours_testing['date'])

# Convert date column to datetime
vaccination_data['date'] = pd.to_datetime(vaccination_data['date'])

# Convert date column to datetime
case_fatality_ratios['date'] = pd.to_datetime(case_fatality_ratios['date'])

# Convert date column to datetime
cases_deaths['date'] = pd.to_datetime(cases_deaths['date'])

# Fill missing values
burden_behaviours_testing['estimate'] = burden_behaviours_testing['estimate'].fillna(0)
burden_behaviours_testing['population'] = burden_behaviours_testing['population'].fillna(0)
burden_behaviours_testing['wbincome2023'] = burden_behaviours_testing['wbincome2023'].fillna("Unknown")

# Fill missing values
vaccination_data['estimate'] = vaccination_data['estimate'].fillna(0)
vaccination_data['population'] = vaccination_data['population'].fillna(0)
vaccination_data['wbincome2023'] = vaccination_data['wbincome2023'].fillna("Unknown")

# Fill missing values
case_fatality_ratios['estimate'] = case_fatality_ratios['estimate'].fillna(0)
case_fatality_ratios['population'] = case_fatality_ratios['population'].fillna(0)
case_fatality_ratios['wbincome2023'] = case_fatality_ratios['wbincome2023'].fillna("Unknown")

# Fill missing values
cases_deaths['estimate'] = cases_deaths['estimate'].fillna(0)
cases_deaths['population'] = cases_deaths['population'].fillna(0)
cases_deaths['wbincome2023'] = cases_deaths['wbincome2023'].fillna("Unknown")

# Standardize column names
burden_behaviours_testing.rename(columns={
    'iso3': 'country_code',
    'indicator_name': 'indicator',
    'subgroup': 'category'
}, inplace=True)

# Standardize column names
vaccination_data.rename(columns={
    'iso3': 'country_code',
    'indicator_name': 'indicator',
    'subgroup': 'category'
}, inplace=True)

# Standardize column names
case_fatality_ratios.rename(columns={
    'iso3': 'country_code',
    'indicator_name': 'indicator',
    'subgroup': 'category'
}, inplace=True)

# Standardize column names
cases_deaths.rename(columns={
    'iso3': 'country_code',
    'indicator_name': 'indicator',
    'subgroup': 'category'
}, inplace=True)

# Save the cleaned dataset
burden_behaviours_testing.to_csv("Cleaned_Burden_Behaviours_Testing.csv", index=False)

# Save the cleaned vaccination data
vaccination_data.to_csv("Cleaned_Vaccination_Data.csv", index=False)

# Save the cleaned CFR data
case_fatality_ratios.to_csv("Cleaned_Case_Fatality_Ratios.csv", index=False)

# Save the cleaned Cases and Deaths data
cases_deaths.to_csv("Cleaned_Cases_Deaths.csv", index=False)

# Verify the cleaned dataset
print(vaccination_data.info())
print(vaccination_data.isnull().sum())
# Verify the cleaned data
print(burden_behaviours_testing.isnull().sum())
print(burden_behaviours_testing.info())
# Verify the cleaned dataset
print(case_fatality_ratios.info())
print(case_fatality_ratios.isnull().sum())
# Verify the cleaned dataset
print(cases_deaths.info())
print(cases_deaths.isnull().sum())

# Merge datasets one by one
merged_data = pd.merge(burden_behaviours_testing, vaccination_data,
                       on=['date', 'country_code', 'indicator'],
                       how='outer', suffixes=('_bbt', '_vax'))

merged_data = pd.merge(merged_data, case_fatality_ratios,
                       on=['date', 'country_code', 'indicator'],
                       how='outer', suffixes=('', '_cfr'))

merged_data = pd.merge(merged_data, cases_deaths,
                       on=['date', 'country_code', 'indicator'],
                       how='outer', suffixes=('', '_cases'))

# Preview the merged dataset
print(merged_data.info())
print(merged_data.head())

# Fill missing values
numeric_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns
categorical_columns = merged_data.select_dtypes(include=['object']).columns

merged_data[numeric_columns] = merged_data[numeric_columns].fillna(0)
merged_data[categorical_columns] = merged_data[categorical_columns].fillna("Unknown")

merged_data.to_csv("Merged_COVID_Data.csv", index=False)

print(merged_data.info())
print(merged_data.isnull().sum())

# Drop redundant columns
columns_to_drop = ['setting_bbt', 'setting_vax', 'setting_cases',
                   'source_bbt', 'source_vax', 'source_cases',
                   'update_bbt', 'update_vax', 'update_cases']
merged_data = merged_data.drop(columns=columns_to_drop)

# Statistical summary of numeric columns
print(merged_data.describe())

# Unique values in key columns
print(merged_data['indicator'].unique())
print(merged_data['country_code'].unique())

import matplotlib.pyplot as plt

# Infection rates over time
plt.figure(figsize=(12, 6))
plt.plot(merged_data['date'], merged_data['estimate_cases'], label='Infection Rates')
plt.xlabel('Date')
plt.ylabel('Infection Rate')
plt.title('Infection Rates Over Time')
plt.legend()
plt.show()

# Vaccination vs Infection
plt.figure(figsize=(12, 6))
plt.scatter(merged_data['estimate_vax'], merged_data['estimate_cases'], alpha=0.5)
plt.xlabel('Vaccination Rate')
plt.ylabel('Infection Rate')
plt.title('Vaccination vs Infection Rates')
plt.show()

# Correlation matrix
correlation_matrix = merged_data[['estimate_cases', 'estimate_vax', 'estimate_bbt']].corr()
print(correlation_matrix)

# Optional: Heatmap
import seaborn as sns
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Matrix')
plt.show()

merged_data.to_csv("Simplified_Merged_COVID_Data.csv", index=False)

# Example for saving the correlation matrix heatmap
plt.savefig("Correlation_Matrix.png")

# Prepare data
data = merged_data[['date', 'country_code', 'estimate_cases', 'estimate_vax', 'estimate_bbt']]
data = data.fillna(0)
data['date'] = pd.to_datetime(data['date'])
data = data.set_index('date')
country_data = data[data['country_code'] == 'USA']  # Example: USA

from sklearn.model_selection import train_test_split

# Assuming 'estimate_cases' is the target variable
X = data.drop('estimate_cases', axis=1)
y = data['estimate_cases']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Define features and target
X = country_data[['estimate_vax', 'estimate_bbt']]
y = country_data['estimate_cases']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Random Forest model
model = RandomForestRegressor()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

country_data['month'] = country_data.index.month
country_data['year'] = country_data.index.year
X = country_data[['estimate_vax', 'estimate_bbt', 'month', 'year']]
country_data['lag_1'] = country_data['estimate_cases'].shift(1)
country_data = country_data.dropna()
X = country_data[['estimate_vax', 'estimate_bbt', 'lag_1']]

from sklearn.linear_model import LinearRegression

# Train a Linear Regression model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Make predictions and evaluate
y_pred_lr = lr_model.predict(X_test)
print("Linear Regression Coefficients:", lr_model.coef_)
print("Mean Squared Error (Linear Regression):", mean_squared_error(y_test, y_pred_lr))

country_data.index = pd.to_datetime(country_data.index)
country_data['month'] = country_data.index.month
country_data['year'] = country_data.index.year
country_data['lag_1'] = country_data['estimate_cases'].shift(1)
country_data['lag_2'] = country_data['estimate_cases'].shift(2)
country_data = country_data.dropna()
# Ensure index is a DatetimeIndex
country_data.index = pd.to_datetime(country_data.index)

# Add time-based features
country_data['month'] = country_data.index.month
country_data['year'] = country_data.index.year

# Add lag features
country_data['lag_1'] = country_data['estimate_cases'].shift(1)
country_data['lag_2'] = country_data['estimate_cases'].shift(2)

# Drop rows with missing values after creating lag features
country_data = country_data.dropna()

# Display updated DataFrame
print(country_data.head())



# Ensure index is a DatetimeIndex
country_data.index = pd.to_datetime(country_data.index)

# Add time-based features
country_data.loc[:, 'month'] = country_data.index.month
country_data.loc[:, 'year'] = country_data.index.year

# Add lag features
country_data.loc[:, 'lag_1'] = country_data['estimate_cases'].shift(1)
country_data.loc[:, 'lag_2'] = country_data['estimate_cases'].shift(2)

# Drop rows with missing values after creating lag features
country_data = country_data.dropna()

# Display updated DataFrame
print(country_data.head())

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt

# Define features and target variable
features = ['estimate_vax', 'estimate_bbt', 'month', 'year', 'lag_1', 'lag_2']
target = 'estimate_cases'

X = country_data[features]
y = country_data[target]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Make predictions
y_pred = rf_model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error: {mse}")

# Feature importance visualization
importances = rf_model.feature_importances_
plt.barh(features, importances)
plt.xlabel("Feature Importance")
plt.ylabel("Features")
plt.title("Feature Importance for Random Forest")
plt.show()

# Scatter plot of actual vs predicted values
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.xlabel("Actual Values")
plt.ylabel("Predicted Values")
plt.title("Actual vs Predicted Values (Random Forest)")
plt.show()

import joblib

# Save the model to a file
joblib.dump(rf_model, "random_forest_model.pkl")
print("Model saved successfully!")

# Create a DataFrame with actual and predicted values
results = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})

# Save to a CSV file
results.to_csv("prediction_results.csv", index=False)
print("Predictions saved successfully!")

# Residuals (difference between actual and predicted)
residuals = y_test - y_pred

# Plot residuals
plt.figure(figsize=(8, 6))
plt.hist(residuals, bins=30, edgecolor='black')
plt.xlabel("Residuals")
plt.ylabel("Frequency")
plt.title("Distribution of Residuals")
plt.show()